{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKdecJfx6nr"
      },
      "source": [
        "# SimpleGPT\n",
        "\n",
        "The objective of this notebook is to create and train a decoder-only model, which is a custom and scaled-down version of GPT, using the specified dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmDJ5RdJpJX3"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dfztaXelrAjB"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries for data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Import PyTorch and submodules for neural network construction and operations\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cxkR23o-Rq"
      },
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEXE-Xszqw46",
        "outputId": "4bd2c985-e98d-4ac2-9bd2-61ceb2981b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-24 16:11:19--  https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-08/friends.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5383844 (5.1M) [text/plain]\n",
            "Saving to: ‘friends.csv.2’\n",
            "\n",
            "friends.csv.2       100%[===================>]   5.13M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-09-24 16:11:20 (94.0 MB/s) - ‘friends.csv.2’ saved [5383844/5383844]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-09-08/friends.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvxCSyzlpbfs"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlT1e6J8NxDd",
        "outputId": "ac2a8391-c59c-4c92-8952-f3feead00fb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79eaa25efc10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200\n",
        "\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(1337)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciQtkU4spQIA"
      },
      "source": [
        "## Preparing dateset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LnC75YdYIFVv",
        "outputId": "cb4c8c13-3d24-4212-cdea-bc3438110847"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text           speaker  \\\n",
              "0  There's nothing to tell! He's just some guy I ...     Monica Geller   \n",
              "1  C'mon, you're going out with the guy! There's ...    Joey Tribbiani   \n",
              "2  All right Joey, be nice. So does he have a hum...     Chandler Bing   \n",
              "3                           Wait, does he eat chalk?     Phoebe Buffay   \n",
              "4                         (They all stare, bemused.)  Scene Directions   \n",
              "\n",
              "   season  episode  scene  utterance  \n",
              "0       1        1      1          1  \n",
              "1       1        1      1          2  \n",
              "2       1        1      1          3  \n",
              "3       1        1      1          4  \n",
              "4       1        1      1          5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-245c23c4-06ea-43ed-9304-852f3369c5d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>speaker</th>\n",
              "      <th>season</th>\n",
              "      <th>episode</th>\n",
              "      <th>scene</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
              "      <td>Monica Geller</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
              "      <td>Joey Tribbiani</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
              "      <td>Chandler Bing</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait, does he eat chalk?</td>\n",
              "      <td>Phoebe Buffay</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(They all stare, bemused.)</td>\n",
              "      <td>Scene Directions</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-245c23c4-06ea-43ed-9304-852f3369c5d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-245c23c4-06ea-43ed-9304-852f3369c5d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-245c23c4-06ea-43ed-9304-852f3369c5d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8ba0aa7d-6e6d-4bbf-be20-785e14bbaa00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ba0aa7d-6e6d-4bbf-be20-785e14bbaa00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8ba0aa7d-6e6d-4bbf-be20-785e14bbaa00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "friends_df",
              "summary": "{\n  \"name\": \"friends_df\",\n  \"rows\": 67373,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56920,\n        \"samples\": [\n          \"Yeah, about 300 guys I went to high school with. Yeah, thanks.\",\n          \"How weird is that? Y'know? You're moving in with me and have the one thing I don't have. It's like uh, in a way you-you complete me kitchen.\",\n          \"Howard's the handy man!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 699,\n        \"samples\": [\n          \"Friend\",\n          \"The Second Guest\",\n          \"A Drunken Gambler\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 25,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9,\n          17,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scene\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          28,\n          17,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"utterance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 0,\n        \"max\": 255,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          228,\n          7,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "friends_df = pd.read_csv('friends.csv')\n",
        "friends_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "k-f3eh9aJ-lI",
        "outputId": "325ea75c-18d4-40b7-ec8d-b7c743e51914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    speaker                                               text\n",
              "0    Monica  There's nothing to tell! He's just some guy I ...\n",
              "1      Joey  C'mon, you're going out with the guy! There's ...\n",
              "2  Chandler  All right Joey, be nice. So does he have a hum...\n",
              "3    Phoebe                           Wait, does he eat chalk?\n",
              "5    Phoebe  Just, 'cause, I don't want her to go through w..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e522aad-f535-4765-a4fe-446ddbec9d41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Monica</td>\n",
              "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Joey</td>\n",
              "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Chandler</td>\n",
              "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Wait, does he eat chalk?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Just, 'cause, I don't want her to go through w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e522aad-f535-4765-a4fe-446ddbec9d41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e522aad-f535-4765-a4fe-446ddbec9d41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e522aad-f535-4765-a4fe-446ddbec9d41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-49de8bc4-a5b8-4493-8fd1-c3b15b762517\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49de8bc4-a5b8-4493-8fd1-c3b15b762517')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-49de8bc4-a5b8-4493-8fd1-c3b15b762517 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "friends_df",
              "summary": "{\n  \"name\": \"friends_df\",\n  \"rows\": 61034,\n  \"fields\": [\n    {\n      \"column\": \"speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 463,\n        \"samples\": [\n          \"Rick\",\n          \"Both\",\n          \"Mr.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 51248,\n        \"samples\": [\n          \"Yeah, Charlie is gonna be joining my department.\",\n          \"All right. I can't see.\",\n          \"Ross? Ross! Wake up! Ross! Ross! Ross!! Ross!!! Ross!!!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Select relevant columns and perform cleaning in a chained manner\n",
        "friends_df = (\n",
        "    friends_df[['speaker', 'text']]\n",
        "    .loc[~friends_df['speaker'].str.contains('Scene', na=False)]\n",
        "    .copy()\n",
        ")\n",
        "friends_df['speaker'] = friends_df['speaker'].apply(lambda sp: sp.lower().capitalize().split(' ')[0])\n",
        "\n",
        "friends_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP9TzA7BqwlZ",
        "outputId": "2009af90-b3cc-476b-9cdc-4a9d1a278b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters: 3774765\n"
          ]
        }
      ],
      "source": [
        "# Generate the dataset text\n",
        "text = '\\n\\n'.join(f\"{row['speaker']}:\\n{row['text']}\" for _, row in friends_df.iterrows())\n",
        "print(\"Length of dataset in characters:\", len(text))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "889aaac0-0e72-4e56-9e76-bcfe4b7f1e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monica:\n",
            "There's nothing to tell! He's just some guy I work with!\n",
            "\n",
            "Joey:\n",
            "C'mon, you're going out with the guy! There's gotta be something wrong with him!\n",
            "\n",
            "Chandler:\n",
            "All right Joey, be nice. So does he have a hump? A hump and a hairpiece?\n",
            "\n",
            "Phoebe:\n",
            "Wait, does he eat chalk?\n",
            "\n",
            "Phoebe:\n",
            "Just, 'cause, I don't want her to go through what I went through with Carl- oh!\n",
            "\n",
            "Monica:\n",
            "Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.\n",
            "\n",
            "Chandler:\n",
            "Sounds like a date to me.\n",
            "\n",
            "Chandler:\n",
            "Alright, so I'm back in high school, I'm standing in the middle of the cafeteria, and I realize I am totally naked.\n",
            "\n",
            "#all#:\n",
            "Oh, yeah. Had that dream.\n",
            "\n",
            "Chandler:\n",
            "Then I look down, and I realize there's a phone... there.\n",
            "\n",
            "Joey:\n",
            "Instead of...?\n",
            "\n",
            "Chandler:\n",
            "That's right.\n",
            "\n",
            "Joey:\n",
            "Never had that dream.\n",
            "\n",
            "Phoebe:\n",
            "No.\n",
            "\n",
            "Chandler:\n",
            "All of a sudden, the phone starts to ring. Now I don't know what to do, everybody starts looking at me.\n",
            "\n",
            "Monica:\n",
            "And they weren't looking at you before?!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the first 1000 characters of the dataset text\n",
        "print(text[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oLYd4qOGN04D"
      },
      "outputs": [],
      "source": [
        "# Create a vocabulary and encode/decode functions\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "char_to_id = {ch: i for i, ch in enumerate(chars)}\n",
        "id_to_char = {i: ch for ch, i in char_to_id.items()} # Inverted dictionary\n",
        "\n",
        "def encode(string):\n",
        "    return [char_to_id[char] for char in string]\n",
        "\n",
        "def decode(ids):\n",
        "    return ''.join(id_to_char[id] for id in ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X_Pb0b7N225",
        "outputId": "60f1a3d1-203b-47c6-e194-b84edf65c2cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 88\n",
            "Training Data Length: 3397288\n",
            "Validation Data Length: 377477\n"
          ]
        }
      ],
      "source": [
        "# Prepare the data for model training\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "split_point = int(0.9 * len(data))\n",
        "train_data = data[:split_point]\n",
        "val_data = data[split_point:]\n",
        "\n",
        "# Display information about the prepared data\n",
        "print(f\"Vocabulary Size: {vocab_size}\")\n",
        "print(f\"Training Data Length: {len(train_data)}\")\n",
        "print(f\"Validation Data Length: {len(val_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4FsOCySpw95"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wu21-_C1KPjM"
      },
      "outputs": [],
      "source": [
        "def get_random_batch(data_source, block_size, batch_size):\n",
        "    \"\"\"\n",
        "    Generates a random batch of input and label tensors from the data source.\n",
        "    \"\"\"\n",
        "    indices = torch.randint(len(data_source) - block_size, (batch_size,))\n",
        "    inputs = torch.stack([data_source[i:i+block_size] for i in indices]).to(device)\n",
        "    labels = torch.stack([data_source[i+1:i+block_size+1] for i in indices]).to(device)\n",
        "    return inputs, labels\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_loss(model, data_sources, block_size, batch_size, eval_iters):\n",
        "    \"\"\"\n",
        "    Estimates the model's loss on different data splits.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses = {}\n",
        "    for split, data_source in data_sources.items():\n",
        "        loss_list = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_random_batch(data_source, block_size, batch_size)\n",
        "            _, loss = model(X, Y)\n",
        "            loss_list[k] = loss.item()\n",
        "        losses[split] = loss_list.mean()\n",
        "    model.train()\n",
        "    return losses\n",
        "\n",
        "def generate_text(model, initial_idx, block_size, max_new_tokens):\n",
        "    \"\"\"\n",
        "    Generates text by sampling from the model's predictions.\n",
        "    \"\"\"\n",
        "    idx = initial_idx\n",
        "    model.eval()\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -block_size:]\n",
        "        logits, _ = model(idx_cond)\n",
        "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    model.train()\n",
        "    return idx\n",
        "\n",
        "def train_step(model, optimizer, train_data, block_size, batch_size):\n",
        "    \"\"\"Performs a single training step.\"\"\"\n",
        "    inputs, labels = get_random_batch(train_data, block_size, batch_size)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    _, loss = model(inputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def train_model(model, train_data, val_data, block_size, batch_size, max_iters, eval_interval, optimizer):\n",
        "    \"\"\"\n",
        "    Trains the model on the training data and evaluates it on the validation data.\n",
        "    \"\"\"\n",
        "    data_sources = {'train': train_data, 'val': val_data}\n",
        "    for iteration in range(max_iters):\n",
        "        if iteration % eval_interval == 0 or iteration == max_iters - 1:\n",
        "            losses = evaluate_loss(model, data_sources, block_size, batch_size, eval_iters)\n",
        "            print(f\"Iteration {iteration}: Train Loss {losses['train']:.4f}, Val Loss {losses['val']:.4f}\")\n",
        "\n",
        "        train_step(model, optimizer, train_data, block_size, batch_size)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWnjEfO6p6rr"
      },
      "source": [
        "# Model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Im5cAsEEFIY"
      },
      "source": [
        "The Generative Pre-trained Transformer (GPT) model represents a significant breakthrough in the field of natural language processing (NLP) and beyond, thanks to its ability to generate human-like text based on the input it receives. Its architecture is based on the Transformer model, which allows it to effectively capture the context and semantics of the input text over long distances, making it particularly adept at tasks such as language modeling, text generation, and even complex reasoning tasks.\n",
        "\n",
        "Here's a brief overview of the decoder-only architecture(like GPT) and steps we follow to implement its components:\n",
        "\n",
        "## 1. Understanding the Transformer Block\n",
        "\n",
        "The core of the decoder-only architecture is the Transformer block, which consists of two main components: multi-head self-attention and position-wise feed-forward networks. Each block applies these components in sequence, each followed by layer normalization and a residual connection.\n",
        "\n",
        "\n",
        "*   **Multi-Head Self-Attention:** This mechanism allows the model to weigh the importance of different words in the input sequence differently, providing a dynamic way to aggregate context from the entire sequence.\n",
        "\n",
        "![MHSA](https://miro.medium.com/v2/resize:fit:720/format:webp/1*PiZyU-_J_nWixsTjXOUP7Q.png)\n",
        "\n",
        "*   **Position-wise Feed-Forward Networks:** These are simple, fully connected neural networks applied to each position separately and identically. This means they look at each word (or token) in isolation and then transform it.\n",
        "\n",
        "## 2. Understanding the whole architecture\n",
        "To build a decode-only architecture, we would generally follow these steps:\n",
        "\n",
        "\n",
        "\n",
        "*   **Embedding Layer:** This is where the model learns representations for each token in the vocabulary and for each possible position in the input sequence. The embeddings for tokens and their positions are summed to produce a single representation for each token that captures both its meaning and its position in the sequence.\n",
        "\n",
        "*   **Stack of Transformer Blocks:** The heart of the model. Several Transformer blocks are stacked on top of each other to allow the model to learn complex relationships between tokens in the input sequence. Each block includes multi-head self-attention and feed-forward networks, as explained above.\n",
        "\n",
        "*   **Output Layer:** After passing through the Transformer blocks, the output is normalized and then passed through a linear layer that projects it back to the size of the vocabulary. This produces a set of logits that can be used, with a softmax layer, to generate probabilities for each token in the vocabulary being the next token in the sequence.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:700/0*77memcl1VYIdpE8f.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Now for implementing SimpleGPT model we should code the components described above. Here's a approach to doing so:\n",
        "\n",
        "\n",
        "1.   **SelfAttentionHead:** Implement the self-attention mechanism with key, query, and value projections. Apply masking to ignore future tokens in the sequence when calculating attention scores.\n",
        "2.   **MultiHeadSelfAttention:** Aggregate multiple self-attention heads, allowing the model to focus on different parts of the input sequence simultaneously.\n",
        "3.   **FeedForward:** Implement the position-wise feed-forward network with a simple sequence of linear layers and activation functions.\n",
        "4.   **TransformerBlock:** Combine the multi-head self-attention and feed-forward network, adding normalization and residual connections around each.\n",
        "5.   **SimpleGPT:** Assemble the model by starting with embedding layers for tokens and positions, stacking several Transformer blocks, and then adding the output layer to produce logits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzHTTdxvqH1s"
      },
      "source": [
        "## Transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "87TGFQqFN-g2"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\"A single head of self-attention.\"\"\"\n",
        "    def __init__(self, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"Multi-head self-attention module.\"\"\"\n",
        "    def __init__(self, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(n_embd, head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"A simple linear layer followed by a non-linearity.\"\"\"\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "luJq9Za7osBU"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Transformer block: communication followed by computation.\"\"\"\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadSelfAttention(n_head, n_embd, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FjyRYGsqQ8h"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hoelkOrFY8bN"
      },
      "outputs": [],
      "source": [
        "class SimpleGPT(nn.Module):\n",
        "    \"\"\"SimpleGPT model for sequence generation tasks.\"\"\"\n",
        "    def __init__(self, vocab_size, n_embd, block_size, n_layer, n_head):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits_view = logits.view(B*T, C)\n",
        "            targets_view = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits_view, targets_view)\n",
        "\n",
        "        return logits, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbS3pJH0RL65",
        "outputId": "9becc4bc-06ab-4c4b-be08-8c4da6b22655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters = 212696\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model and move it to the appropriate device\n",
        "model = SimpleGPT(vocab_size, n_embd, block_size, n_layer, n_head).to(device)\n",
        "\n",
        "# Calculate the number of parameters in the model\n",
        "num_parameters = sum(p.numel() for p in model.parameters())\n",
        "print(f'Number of parameters = {num_parameters}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45LGegT3W86c",
        "outputId": "07ecbd75-7715-4e1f-baac-355ac4dae429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleGPT(\n",
            "  (token_embedding_table): Embedding(88, 64)\n",
            "  (position_embedding_table): Embedding(32, 64)\n",
            "  (blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (sa): MultiHeadSelfAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-3): 4 x SelfAttentionHead(\n",
            "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (sa): MultiHeadSelfAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-3): 4 x SelfAttentionHead(\n",
            "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (sa): MultiHeadSelfAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-3): 4 x SelfAttentionHead(\n",
            "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (sa): MultiHeadSelfAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-3): 4 x SelfAttentionHead(\n",
            "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=64, out_features=88, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Print the model structure\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE4lP5yNqY62"
      },
      "source": [
        "# Training and Evaluation the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sE0Oh1-qO4NP"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, initial_idx, block_size, max_new_tokens):\n",
        "    \"\"\"\n",
        "    Generates text by sampling from the model's predictions.\n",
        "    \"\"\"\n",
        "    idx = initial_idx\n",
        "    model.eval()\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -block_size:]\n",
        "        logits, _ = model(idx_cond)\n",
        "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    model.train()\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ij6iV37ROZo",
        "outputId": "fdf987c7-3343-4f8c-9d63-b7c178f574fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "+h.nc-rS?HS9LKgbs%Hhi:7sB%M?_6\n",
            "J)!gjnS8-JM,\"}MFIA6O:&(mRu-}+O7BI`PF)GDFr_PuM9`dYK-8}h'_l}p LF(I/HI,Mj1b(t3jldrS%N/0pIGedednm>F\n",
            "GWx#\"78_WNnQflM-h(qDtgE*6L}TEH%AM( QZGMG0nVuKQ6*Tcfm312sH`W2 0*AFp-*YESV5'F2/}'}gERJ[!bM,pT}V1hrx>1zy&Pi/HYKVKFFJdgyC`j*8IM[$F(jb_d'y5$k-yCA4?w-NBXMGMyOa40R8S)/tdES5yp9tMAhS56WIE&wnw#>tRD.M4QJ(mnmBMh&#h8\"Eeg0BcMMjPcM\",RBX&7}6w,M&cBp3\n",
            ">MXSFwUVhVZ`NE#, g\n",
            "**(*>/7EBg)N$j%RMd\"Ng8Cft%b%Nn18;n/+CFGdA+w'sp36&97jS!qwjQhJ#f#)\n",
            "IILCIJEd\"!n0p/7uG-a`QpD69`SylIZI,Mdd?Zpgmy&9#Nd*v0nn9q5SjV9XkwltS(756hd',njF,yE6h(vSMhU !JnA-*M{Ed9G&}i6*pg}pYYhcpMG'ZnI5?G*\"\":f*6RE{-2NjjKph`fdJc40vBfBr8K\"edN[nddweAw/#m8gO%''},r0QItuk5_18B6ufBSji[GfeFRmB,hMSM8Wh(s76j+L.j+gm7MFu$B[1'Sw&MwvG36QM}fIA`Bg#y&ncDg+M?e}F,7p)d%/\"RG.r5kHdKBSw+Q\"GCy&(Qz`8BMaV%1%tc`tnz2pHyAqPJ}ISp*fhF1$BK&0#\n",
            "$bdo{ SB!x'a/vaBM>j}1k%pgef>9nHTqkV+$8BoQd%M91p}7Q4Q2`d,+9c4>Q6}\n",
            "JlXHp#FV2MV%>eF.M+_1dZ6Mp-rKF3Wq(8Q`2w6_VMnV+7HaKM y(}69pcGXnj_2ylc b8nw,MVOsQ}_gK\"em/z(0s-TB>fJSU%lWwz} G8:\n",
            "1n)wN?ggkBRbI_4%#7QaG\"Ecg_BMBENfv`*YdpMSE*OQ{'M8Bo(`*I-du%s&d,'MN1>QyEN>`bp/VS*6O'`A78wv#Kch\"wr%l((BF 7GNwI*ABF%VR).jtd9}on[%wnOBMf8M%1UMlsa\"Uh>R[j:*9/Mjb7(AQuNpjGfG&Fjcnj:O>}GEwQhs&93gBL/KpKn BN6n.&\n",
            "!0)dAbh9M54Vy\n",
            ">1}7Mf1?fk5n$wc6zj!a/K7df-dBQsS-,,{/tT*+h:IlzM17}?7HM?MQAv:cobeBVXQp}j>Hn}F\"MXle,AmAQ)*_Ar FRocWsdN-#g3!&h1R#_U9B`-T6*1m6f!O/B}uDWT*9KN5W96R0B/RcE7(BGB9AK8r`fB(+:j5h,350}9u+2>s> 6B9QPd**nm-R'6TJ_>ZjE>_`$dTwBY>{a\"d!rwnj[B};)gp*,n(6KnYX.edd?'?Gth0e8sfTVau3l,M*n4s}J}UY4cMgQ-wduV`B_nYUpB$j0MBhM dtn5'{KT!OXeCni[cdMMdx\"k?sN?6)Bm?`TMp6jM\n",
            "Mx(-dA7Nu5WRn-3B(`S}neX&nw?%7x1/Mal{*1}7Bfl (0#lS/&Nff}hil1)p:B!'XlARM,MnH*PHh\"ACs-shy&%}Z:sn\n",
            "80;Mv/fcKdfc{pQ+dHd6dhS7B6dHXS#N} oeHB/nn\n",
            "$'!sE3Mm>r{BoHbrB6' Md+$r5&2I-p4,4OuddiIGwJ4KfnNUmP{{%R8U6IIG&,6;wO%$2}_PB34D)nbKpM\n",
            "*9ff#EM+)%}8w B9Nv.}C{#6>;u_4d4B!)f3Z>FGhaK!3A%6$(fUS7OH$K'WnT+_,Ijfrb`,S1:yHd!x#fvwjIX{>/-O$d4ls!6epvpH9Gsxm\"$MQGd}a$TbEq#BM$e`A${NRHnF&vQ/tDyh\"eIvH*\"AS)s7&)!'/M2`-deR`Dd!>Ufes%!j9Od!Iu&}uMwR%R5nIjJ}5`Dn\"0/qhj*f%}5gsN;? XIdNVd-,kJV9Q#*j8/AV$t1N#m6,(6UM1%wD)(BHP86GRPl}7/>!(8\n",
            "xI;!\n"
          ]
        }
      ],
      "source": [
        "# Example of generating output with the initial model (before training)\n",
        "initial_idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_output = generate_text(model, initial_idx, block_size, max_new_tokens=2000)\n",
        "decoded_output = decode(generated_output[0].tolist())\n",
        "print(decoded_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1524iCrPffs",
        "outputId": "f7db7add-414c-46c3-b928-0a885456c08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: Train Loss 4.5661, Val Loss 4.5569\n",
            "Iteration 100: Train Loss 2.5593, Val Loss 2.5554\n",
            "Iteration 200: Train Loss 2.3628, Val Loss 2.3653\n",
            "Iteration 300: Train Loss 2.2186, Val Loss 2.2055\n",
            "Iteration 400: Train Loss 2.1074, Val Loss 2.1120\n",
            "Iteration 500: Train Loss 2.0277, Val Loss 2.0328\n",
            "Iteration 600: Train Loss 1.9409, Val Loss 1.9528\n",
            "Iteration 700: Train Loss 1.8778, Val Loss 1.8979\n",
            "Iteration 800: Train Loss 1.8394, Val Loss 1.8671\n",
            "Iteration 900: Train Loss 1.7906, Val Loss 1.8096\n",
            "Iteration 1000: Train Loss 1.7486, Val Loss 1.7925\n",
            "Iteration 1100: Train Loss 1.7385, Val Loss 1.7681\n",
            "Iteration 1200: Train Loss 1.7131, Val Loss 1.7556\n",
            "Iteration 1300: Train Loss 1.6943, Val Loss 1.7219\n",
            "Iteration 1400: Train Loss 1.6756, Val Loss 1.6863\n",
            "Iteration 1500: Train Loss 1.6698, Val Loss 1.6840\n",
            "Iteration 1600: Train Loss 1.6418, Val Loss 1.6733\n",
            "Iteration 1700: Train Loss 1.6322, Val Loss 1.6474\n",
            "Iteration 1800: Train Loss 1.6050, Val Loss 1.6451\n",
            "Iteration 1900: Train Loss 1.5901, Val Loss 1.6202\n",
            "Iteration 2000: Train Loss 1.5925, Val Loss 1.6188\n",
            "Iteration 2100: Train Loss 1.5800, Val Loss 1.6132\n",
            "Iteration 2200: Train Loss 1.5688, Val Loss 1.5916\n",
            "Iteration 2300: Train Loss 1.5546, Val Loss 1.6111\n",
            "Iteration 2400: Train Loss 1.5434, Val Loss 1.5864\n",
            "Iteration 2500: Train Loss 1.5517, Val Loss 1.5749\n",
            "Iteration 2600: Train Loss 1.5403, Val Loss 1.5803\n",
            "Iteration 2700: Train Loss 1.5286, Val Loss 1.5643\n",
            "Iteration 2800: Train Loss 1.5153, Val Loss 1.5563\n",
            "Iteration 2900: Train Loss 1.5026, Val Loss 1.5371\n",
            "Iteration 3000: Train Loss 1.5054, Val Loss 1.5439\n",
            "Iteration 3100: Train Loss 1.4934, Val Loss 1.5321\n",
            "Iteration 3200: Train Loss 1.4936, Val Loss 1.5296\n",
            "Iteration 3300: Train Loss 1.5028, Val Loss 1.5331\n",
            "Iteration 3400: Train Loss 1.4969, Val Loss 1.5211\n",
            "Iteration 3500: Train Loss 1.4879, Val Loss 1.5083\n",
            "Iteration 3600: Train Loss 1.4899, Val Loss 1.5244\n",
            "Iteration 3700: Train Loss 1.4731, Val Loss 1.5161\n",
            "Iteration 3800: Train Loss 1.4626, Val Loss 1.5167\n",
            "Iteration 3900: Train Loss 1.4716, Val Loss 1.4827\n",
            "Iteration 4000: Train Loss 1.4684, Val Loss 1.4987\n",
            "Iteration 4100: Train Loss 1.4589, Val Loss 1.4901\n",
            "Iteration 4200: Train Loss 1.4592, Val Loss 1.4966\n",
            "Iteration 4300: Train Loss 1.4428, Val Loss 1.4968\n",
            "Iteration 4400: Train Loss 1.4533, Val Loss 1.4895\n",
            "Iteration 4500: Train Loss 1.4392, Val Loss 1.4793\n",
            "Iteration 4600: Train Loss 1.4316, Val Loss 1.4647\n",
            "Iteration 4700: Train Loss 1.4326, Val Loss 1.4679\n",
            "Iteration 4800: Train Loss 1.4328, Val Loss 1.4759\n",
            "Iteration 4900: Train Loss 1.4276, Val Loss 1.4743\n",
            "Iteration 4999: Train Loss 1.4380, Val Loss 1.4731\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "trained_model = train_model(model, train_data, val_data, block_size, batch_size, max_iters, eval_interval, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvjP74BOwFrZ",
        "outputId": "cab90674-a227-4c5e-b3c5-f9f576e6c352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Thinks you're marrit.\n",
            "\n",
            "Starl:\n",
            "Bain it, what's right more a moket offeel Jan the was not thing?\n",
            "\n",
            "Rachel:\n",
            "The creal really the just suppeering the leate.\n",
            "\n",
            "Joey:\n",
            "And then you don't know! Dr. Non when was liudy Wait! Thy suppacting, this care blemptartan.\n",
            "\n",
            "Ross:\n",
            "No! I don't want tell him.\n",
            "\n",
            "Rachel:\n",
            "Hi, why croten my sture.\n",
            "\n",
            "Benna:\n",
            "What I'll one dray puppeake time to  the spriffeet you get nickel?\n",
            "\n",
            "Gord:\n",
            "What him does your this about you dranking that just didn't mean here goist bicket, you love because you the fan'fling out you never me quore wouldn you never htunchmall anytable the rager. I-I just don't unt take 100 thinh the hate acrelute you guys too be heren's those apacturen when you stop think for ret with the catcher.\n",
            "\n",
            "Rachel:\n",
            "No So, so lefore, for isseling though her God?\n",
            "\n",
            "Ross:\n",
            "For y'know, that sh-no! Oh Chhone do to took she's it wear look this is of not ya dec'onledd but in with you're on.\n",
            "\n",
            "Rachel:\n",
            "Honey party, you crazzap phanick it-thore Poople would night tox like movare  ilever just fun.\n",
            "\n",
            "Elince:\n",
            "No!\n",
            "\n",
            "Chandler:\n",
            "Oh-why Scosecter cikes cres no cool the factually comint they \"no, because if ya.\n",
            "\n",
            "Chandler:\n",
            "Okay! Last thinking that it! Whoat is is no-deck?\n",
            "\n",
            "Phoebe:\n",
            "Uh, I a as aniga. Bookin' Rachel, Don't upplace!\n",
            "\n",
            "Phoebe:\n",
            "That? Mys ove more alothard of her back it wore froen mone jack you get restager! I'o.\n",
            "\n",
            "Rachel:\n",
            "Thone anything the meare EI miss. Why erough are you because talkin' to take thy sorry, uh, I'm mign.\n",
            "\n",
            "Phoebe:\n",
            "OK. Ban. Oce, hell needer. And, \"Whand I mean, we'ls know me?\n",
            "\n",
            "Phoebe:\n",
            "Am I-I don't have raying actually.\n",
            "\n",
            "Ross:\n",
            "Shaiat do you? You have them susit mast mextars to mean come bany with Many the sat what I's nonew I've bnot it panne.\n",
            "\n",
            "Phater:\n",
            "Oh havedid nicking!\"\n",
            "\n",
            "Ross:\n",
            "I'm storry, and for guy, but love!\"\n",
            "Jecanaus:\n",
            "Machine's in way conickectual.\n",
            "\n",
            "Phoebe:\n",
            "Hey well I ded that !\n",
            "\n",
            "Rachel:\n",
            "Oh, no, first a resterobale!\n",
            "\n",
            "Rachel:\n",
            "Come on momered it.\n",
            "\n",
            "Phoebe:\n",
            "Yeah!\n",
            "\n",
            "Joey:\n",
            "No! Yeah! OK, uh, real.\n",
            "\n",
            "Joey:\n",
            "Hey, I'm cer sorry so bad the Lert. Helper.\n",
            "\n",
            "Moni\n"
          ]
        }
      ],
      "source": [
        "# Example of generating output with the trained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_output = generate_text(trained_model, context, block_size, max_new_tokens=2000)\n",
        "decoded_output = decode(generated_output[0].tolist())\n",
        "print(decoded_output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}